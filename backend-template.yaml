AWSTemplateFormatVersion: '2010-09-09'
Description: 'Backend Infrastructure for Financial News Engine'

Parameters:
  EnvironmentName:
    Description: Environment name
    Type: String
    Default: production
    AllowedValues:
      - development
      - staging
      - production
  
  BackendDomainName:
    Description: Custom domain name for the backend ALB (e.g., api.yourdomain.com)
    Type: String
    Default: ""
  
  CorsAllowedOrigins:
    Description: Comma-separated list of domains allowed to access the API (e.g., financialnewsengine.com,www.financialnewsengine.com)
    Type: String
    Default: "*"
  
  VpcStackName:
    Description: Name of the VPC CloudFormation stack
    Type: String
    Default: financial-news-vpc
  
  InstanceType:
    Description: EC2 instance type for the backend servers
    Type: String
    Default: t3.micro
    AllowedValues:
      - t3.micro
      - t3.small
      - t3.medium
      - t3.large
  
  KeyName:
    Description: Name of an existing EC2 KeyPair to enable SSH access to the instances
    Type: AWS::EC2::KeyPair::KeyName
    ConstraintDescription: Must be the name of an existing EC2 KeyPair.
  
  AMIId:
    Description: AMI ID for the EC2 instances
    Type: AWS::EC2::Image::Id
    Default: ami-0261755bbcb8c4a84  # Ubuntu 20.04 LTS in us-east-1 (update for your region)
  
  ElasticsearchEndpoint:
    Description: Endpoint URL for Elasticsearch
    Type: String
    Default: https://your-elasticsearch-endpoint.es.amazonaws.com
  
  ElasticsearchApiKey:
    Description: API Key for Elasticsearch
    Type: String
    NoEcho: true
  
  ElasticsearchIndex:
    Description: Elasticsearch index name
    Type: String
    Default: financial_news
  
  EsNumberOfShards:
    Description: Number of shards for Elasticsearch index
    Type: Number
    Default: 3
  
  EsNumberOfReplicas:
    Description: Number of replicas for Elasticsearch index
    Type: Number
    Default: 2
  
  MinSize:
    Description: Minimum number of EC2 instances in the Auto Scaling Group
    Type: Number
    Default: 2
    MinValue: 1
  
  MaxSize:
    Description: Maximum number of EC2 instances in the Auto Scaling Group
    Type: Number
    Default: 6
    MinValue: 1
  
  DesiredCapacity:
    Description: Desired number of EC2 instances in the Auto Scaling Group
    Type: Number
    Default: 2
    MinValue: 1
  
  SSHLocation:
    Description: The IP address range that can be used to SSH to the EC2 instances
    Type: String
    MinLength: 9
    MaxLength: 18
    Default: 0.0.0.0/0
    AllowedPattern: (\d{1,3})\.(\d{1,3})\.(\d{1,3})\.(\d{1,3})/(\d{1,2})
  
  SSLCertificateArn:
    Description: ARN of the SSL certificate from AWS Certificate Manager
    Type: String
    Default: "arn:aws:acm:us-east-1:YOUR_ACCOUNT_ID:certificate/YOUR_CERTIFICATE_ID"

Conditions:
  HasDomainName: !Not [!Equals [!Ref BackendDomainName, ""]]

Mappings:
  RegionMap:
    us-east-1:
      AMI: ami-0261755bbcb8c4a84  # Ubuntu 20.04 LTS
    us-east-2:
      AMI: ami-0430580de6244e02e  # Ubuntu 20.04 LTS
    us-west-1:
      AMI: ami-04669a22aad391419  # Ubuntu 20.04 LTS
    us-west-2:
      AMI: ami-0efa651876de2a5ce  # Ubuntu 20.04 LTS
    eu-west-1:
      AMI: ami-0a8e758f5e873d1c1  # Ubuntu 20.04 LTS

Resources:
  # SSL Certificate
  SSLCertificate:
    Type: AWS::CertificateManager::Certificate
    Condition: HasDomainName
    Properties:
      DomainName: !Ref BackendDomainName
      ValidationMethod: DNS
      Tags:
        - Key: Name
          Value: !Sub ${EnvironmentName}-backend-certificate
        - Key: Environment
          Value: !Ref EnvironmentName

  # IAM Role for EC2 instances
  BackendInstanceRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: ec2.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore
        - arn:aws:iam::aws:policy/CloudWatchAgentServerPolicy
      Path: /
      Policies:
        - PolicyName: ESAccessPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - 'es:ESHttpGet'
                  - 'es:ESHttpPost'
                  - 'es:ESHttpPut'
                  - 'es:ESHttpDelete'
                Resource: '*'
        - PolicyName: S3AccessPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - 's3:GetObject'
                  - 's3:ListBucket'
                Resource: 
                  - 'arn:aws:s3:::financial-news-assets/*'
                  - 'arn:aws:s3:::financial-news-assets'

  # Instance Profile for EC2 instances
  BackendInstanceProfile:
    Type: AWS::IAM::InstanceProfile
    Properties:
      Path: /
      Roles:
        - !Ref BackendInstanceRole

  # Security Group for Backend EC2 instances
  BackendSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Security group for backend servers
      VpcId: 
        Fn::ImportValue: !Sub "${VpcStackName}-VPCID"
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 22
          ToPort: 22
          CidrIp: !Ref SSHLocation
        - IpProtocol: tcp
          FromPort: 5000  # Flask default port
          ToPort: 5000
          SourceSecurityGroupId: !Ref LoadBalancerSecurityGroup
      Tags:
        - Key: Name
          Value: !Sub ${EnvironmentName}-backend-sg
        - Key: Environment
          Value: !Ref EnvironmentName
      # Reference the App Server Security Group from VPC Stack for additional security rules
      SecurityGroupEgress:
        - IpProtocol: -1
          CidrIp: 0.0.0.0/0
          Description: Allow all outbound traffic

  # Security Group for Application Load Balancer
  LoadBalancerSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Security group for Application Load Balancer
      VpcId:
        Fn::ImportValue: !Sub "${VpcStackName}-VPCID"
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: 0.0.0.0/0
        - IpProtocol: tcp
          FromPort: 443
          ToPort: 443
          CidrIp: 0.0.0.0/0
      Tags:
        - Key: Name
          Value: !Sub ${EnvironmentName}-alb-sg
        - Key: Environment
          Value: !Ref EnvironmentName

  # Launch Template for Auto Scaling Group
  BackendLaunchTemplate:
    Type: AWS::EC2::LaunchTemplate
    Metadata:
      AWS::CloudFormation::Init:
        configSets:
          default:
            - install_packages
            - configure_app
            - configure_services
            - start_services
        
        install_packages:
          packages:
            apt:
              python3: []
              python3-pip: []
              python3-dev: []
              git: []
              wget: []
              curl: []
              jq: []
          commands:
            01_install_cloudwatch_agent:
              command: |
                if [ ! -f "/opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-ctl" ]; then
                  wget https://s3.amazonaws.com/amazoncloudwatch-agent/ubuntu/amd64/latest/amazon-cloudwatch-agent.deb -O /tmp/amazon-cloudwatch-agent.deb
                  dpkg -i /tmp/amazon-cloudwatch-agent.deb
                else
                  echo "CloudWatch agent already installed"
                fi
        
        configure_app:
          files:
            /opt/financial-news-engine/app.py:
              content: |
                from flask import Flask, jsonify, request
                from flask_cors import CORS
                import os
                import logging
                import sys
                import json
                import time
                from datetime import datetime
                
                # Configure logging
                log_dir = "logs"
                if not os.path.exists(log_dir):
                    os.makedirs(log_dir)
                    
                logger = logging.getLogger("backend")
                logger.setLevel(logging.INFO)
                
                # Create console handler
                ch = logging.StreamHandler(sys.stdout)
                ch.setLevel(logging.INFO)
                
                # Create file handler
                fh = logging.FileHandler(os.path.join(log_dir, "backend.log"))
                fh.setLevel(logging.INFO)
                
                # Create formatter and add to handlers
                formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
                ch.setFormatter(formatter)
                fh.setFormatter(formatter)
                
                # Add handlers to logger
                logger.addHandler(ch)
                logger.addHandler(fh)
                
                # Create Flask app
                app = Flask(__name__)
                
                # Setup CORS - make sure it supports all routes
                cors_origins = os.environ.get('CORS_ALLOWED_ORIGINS', '*')
                if cors_origins != '*':
                    # If specific origins are provided, split the comma-separated list
                    cors_origins = [origin.strip() for origin in cors_origins.split(',')]
                    # Enable credentials only with specific origins
                    CORS(app, resources={r"/*": {"origins": cors_origins}}, supports_credentials=True)
                else:
                    # For wildcard origins, don't use credentials to avoid browser issues
                    CORS(app, resources={r"/*": {"origins": cors_origins}})
                
                # Log CORS configuration
                logger.info(f"CORS configured with origins: {cors_origins}")
                
                # Load environment variables
                es_url = os.environ.get('ELASTICSEARCH_URL')
                es_api_key = os.environ.get('ELASTICSEARCH_API_KEY')
                es_index = os.environ.get('ELASTICSEARCH_INDEX')
                
                # Add a global OPTIONS route handler for CORS preflight requests
                @app.route('/', defaults={'path': ''}, methods=['OPTIONS'])
                @app.route('/<path:path>', methods=['OPTIONS'])
                def handle_options(path):
                    response = app.make_default_options_response()
                    # Explicitly add required CORS headers for preflight
                    response.headers['Access-Control-Allow-Methods'] = 'GET, POST, PUT, DELETE, OPTIONS'
                    response.headers['Access-Control-Allow-Headers'] = 'Content-Type, Authorization'
                    response.headers['Access-Control-Max-Age'] = '3600'  # Cache preflight response for 1 hour
                    return response
                
                @app.route('/health', methods=['GET'])
                def health():
                    """Health check endpoint"""
                    status = {
                        "status": "healthy",
                        "timestamp": datetime.now().isoformat(),
                        "version": "1.0",
                        "environment": os.environ.get('ENVIRONMENT', 'development')
                    }
                    
                    # Add Elasticsearch connection status if configured
                    if es_url and es_api_key:
                        try:
                            # Import here to avoid requiring the package if not used
                            from elasticsearch import Elasticsearch
                            
                            # Test connection with a short timeout
                            es = Elasticsearch([es_url], api_key=es_api_key, request_timeout=5)
                            es_info = es.info()
                            
                            status["elasticsearch"] = {
                                "connected": True,
                                "version": es_info.get("version", {}).get("number", "unknown")
                            }
                        except Exception as e:
                            status["elasticsearch"] = {
                                "connected": False,
                                "error": str(e)
                            }
                            # Mark as degraded if ES connection fails
                            status["status"] = "degraded"
                            logger.warning(f"Elasticsearch connection failed: {str(e)}")
                    else:
                        status["elasticsearch"] = {
                            "connected": False,
                            "error": "Not configured"
                        }
                    
                    return jsonify(status)
                
                @app.route('/diagnostic/health', methods=['GET'])
                def diagnostic_health():
                    """Diagnostic health check endpoint - frontend expects this route"""
                    return health()
                
                @app.route('/diagnostic', methods=['GET'])
                def diagnostic():
                    """Diagnostic information endpoint"""
                    import platform
                    import socket
                    import psutil
                    
                    # Collect system information
                    system_info = {
                        "hostname": socket.gethostname(),
                        "platform": platform.system(),
                        "platform_version": platform.version(),
                        "python_version": platform.python_version(),
                        "cpu_percent": psutil.cpu_percent(),
                        "memory_percent": psutil.virtual_memory().percent,
                        "disk_percent": psutil.disk_usage('/').percent
                    }
                    
                    # Add environment variables (redacted)
                    env_vars = {}
                    for key, value in os.environ.items():
                        if key.lower() in ('api_key', 'key', 'secret', 'password', 'token'):
                            env_vars[key] = '***REDACTED***'
                        else:
                            env_vars[key] = value
                    
                    return jsonify({
                        "system": system_info,
                        "environment": env_vars,
                        "timestamp": datetime.now().isoformat()
                    })
                
                @app.route('/diagnostic/report', methods=['GET'])
                def diagnostic_report():
                    """Diagnostic report endpoint - frontend expects this route"""
                    import platform
                    import socket
                    import psutil
                    
                    # Collect system information
                    system_info = {
                        "hostname": socket.gethostname(),
                        "platform": platform.system(),
                        "platform_version": platform.version(),
                        "python_version": platform.python_version(),
                        "cpu_percent": psutil.cpu_percent(),
                        "memory_percent": psutil.virtual_memory().percent,
                        "disk_percent": psutil.disk_usage('/').percent
                    }
                    
                    # Add environment variables (redacted)
                    env_vars = {}
                    for key, value in os.environ.items():
                        if key.lower() in ('api_key', 'key', 'secret', 'password', 'token'):
                            env_vars[key] = '***REDACTED***'
                        else:
                            env_vars[key] = value
                    
                    # More detailed report with additional data
                    return jsonify({
                        "system": system_info,
                        "environment": env_vars,
                        "timestamp": datetime.now().isoformat(),
                        "memory": {
                            "total": psutil.virtual_memory().total,
                            "available": psutil.virtual_memory().available,
                            "used": psutil.virtual_memory().used,
                            "percent": psutil.virtual_memory().percent
                        },
                        "cpu": {
                            "percent": psutil.cpu_percent(interval=0.1, percpu=True),
                            "count": psutil.cpu_count(),
                            "physical_count": psutil.cpu_count(logical=False) or 0
                        },
                        "disk": {
                            "total": psutil.disk_usage('/').total,
                            "used": psutil.disk_usage('/').used,
                            "free": psutil.disk_usage('/').free,
                            "percent": psutil.disk_usage('/').percent
                        },
                        "network": {
                            "hostname": socket.gethostname(),
                            "ip": socket.gethostbyname(socket.gethostname())
                        }
                    })
                
                @app.route('/query', methods=['GET'])
                def query():
                    """Search endpoint for querying articles"""
                    query_text = request.args.get('query', '')
                    source = request.args.get('source', None)
                    time_range = request.args.get('time_range', None)
                    sentiment = request.args.get('sentiment', None)
                    sort_by = request.args.get('sort_by', 'relevance')  # Default to relevance sorting
                    
                    logger.info(f"Search query received: {query_text}, filters: source={source}, time_range={time_range}, sentiment={sentiment}, sort_by={sort_by}")
                    
                    # Check if Elasticsearch is configured
                    if es_url and es_api_key and es_index:
                        try:
                            from elasticsearch import Elasticsearch
                            
                            # Setup Elasticsearch client
                            es = Elasticsearch([es_url], api_key=es_api_key, request_timeout=10)
                            
                            # Build Elasticsearch query
                            must_conditions = []
                            filter_conditions = []
                            
                            # Add text search if query provided
                            if query_text:
                                must_conditions.append({
                                    "multi_match": {
                                        "query": query_text,
                                        "fields": [
                                            "headline^3",  # Boost headline matches
                                            "summary^2",   # Boost summary matches
                                            "content",
                                            "companies.name^2"
                                        ],
                                        "fuzziness": "AUTO"
                                    }
                                })
                            
                            # Add filters
                            if source:
                                filter_conditions.append({
                                    "term": {"source": source}
                                })
                            
                            if sentiment:
                                filter_conditions.append({
                                    "term": {"sentiment": sentiment}
                                })
                            
                            if time_range:
                                # Convert time range to Elasticsearch date range
                                if time_range == '24h':
                                    time_filter = "now-1d"
                                elif time_range == '7d':
                                    time_filter = "now-7d"
                                elif time_range == '30d':
                                    time_filter = "now-30d"
                                elif time_range == '90d':
                                    time_filter = "now-90d"
                                else:
                                    time_filter = None
                                    
                                if time_filter:
                                    filter_conditions.append({
                                        "range": {
                                            "published_at": {"gte": time_filter}
                                        }
                                    })
                            
                            # Set up sorting based on sort_by parameter
                            sort_config = []
                            if sort_by == 'date':
                                sort_config = [{"published_at": {"order": "desc"}}]
                            elif sort_by == 'relevance':
                                sort_config = [{"_score": {"order": "desc"}}]
                            elif sort_by == 'sentiment':
                                sort_config = [{"sentiment_score": {"order": "desc"}}]
                            else:
                                # Default sorting: relevance first, then date
                                sort_config = [
                                    {"_score": {"order": "desc"}},
                                    {"published_at": {"order": "desc"}}
                                ]
                            
                            # Create the full query
                            es_query = {
                                "query": {
                                    "bool": {
                                        "must": must_conditions if must_conditions else [{"match_all": {}}],
                                        "filter": filter_conditions
                                    }
                                },
                                "highlight": {
                                    "fields": {
                                        "headline": {},
                                        "summary": {},
                                        "content": {}
                                    }
                                },
                                "sort": sort_config,
                                "size": 50  # Return up to 50 results
                            }
                            
                            # Execute search
                            response = es.search(index=es_index, body=es_query)
                            
                            # Extract and return results
                            return jsonify(response["hits"]["hits"])
                        
                        except Exception as e:
                            logger.error(f"Elasticsearch search error: {str(e)}")
                            # Fall back to mock results if Elasticsearch fails
                            return jsonify(generate_mock_results(query_text, source, time_range, sentiment, sort_by))
                    else:
                        # If Elasticsearch is not configured, return mock results
                        logger.info("Elasticsearch not configured, returning mock results")
                        return jsonify(generate_mock_results(query_text, source, time_range, sentiment, sort_by))
                
                def generate_mock_results(query_text, source=None, time_range=None, sentiment=None, sort_by='relevance'):
                    """Generate mock search results for testing"""
                    import random
                    from datetime import datetime, timedelta
                    
                    # Sample list of sources
                    sources = ["Reuters", "Bloomberg", "Wall Street Journal", "CNBC", "Financial Times"]
                    
                    # Sample list of companies
                    companies = ["Apple", "Tesla", "Microsoft", "Amazon", "Google", "Meta", "Netflix"]
                    
                    # Sample sentiments
                    sentiments = ["positive", "negative", "neutral"]
                    
                    # Configure number of results
                    num_results = random.randint(8, 15)
                    if source:
                        # Filter to only include requested source
                        mock_source = source
                    else:
                        mock_source = None
                    
                    results = []
                    for i in range(num_results):
                        # Generate base article
                        article_source = mock_source if mock_source else random.choice(sources)
                        company = random.choice(companies)
                        article_sentiment = sentiment if sentiment else random.choice(sentiments)
                        
                        # Generate published date based on time range
                        if time_range == '24h':
                            hours_ago = random.randint(1, 24)
                            published_date = (datetime.now() - timedelta(hours=hours_ago)).isoformat()
                        elif time_range == '7d':
                            days_ago = random.randint(1, 7)
                            published_date = (datetime.now() - timedelta(days=days_ago)).isoformat()
                        elif time_range == '30d':
                            days_ago = random.randint(1, 30)
                            published_date = (datetime.now() - timedelta(days=days_ago)).isoformat()
                        else:
                            days_ago = random.randint(1, 90)
                            published_date = (datetime.now() - timedelta(days=days_ago)).isoformat()
                        
                        # Generate sentiment score based on sentiment
                        if article_sentiment == "positive":
                            sentiment_score = random.uniform(0.3, 1.0)
                        elif article_sentiment == "negative":
                            sentiment_score = random.uniform(-1.0, -0.3)
                        else:
                            sentiment_score = random.uniform(-0.3, 0.3)
                        
                        # Ensure query text appears in results if provided
                        headline_prefix = ""
                        if query_text and random.random() > 0.3:  # 70% chance to include query in headline
                            headline_prefix = f"{query_text}: "
                        
                        article = {
                            "_id": f"mock-article-{i}",
                            "_source": {
                                "headline": f"{headline_prefix}{company} Reports Strong Financial Results",
                                "summary": f"A brief summary about {company}'s financial performance.",
                                "url": f"https://example.com/article/{i}",
                                "source": article_source,
                                "published_at": published_date,
                                "sentiment": article_sentiment,
                                "sentiment_score": sentiment_score,
                                "companies": [
                                    {
                                        "name": company,
                                        "ticker": company[:4].upper()
                                    }
                                ]
                            }
                        }
                        results.append(article)
                    
                    # Apply sorting to mock results
                    if sort_by == 'date':
                        results.sort(key=lambda x: x["_source"]["published_at"], reverse=True)
                    elif sort_by == 'sentiment':
                        results.sort(key=lambda x: x["_source"]["sentiment_score"], reverse=True)
                    # For 'relevance', we keep the default order with query matches prioritized
                    
                    return results
                
                @app.route('/ping', methods=['GET'])
                def ping():
                    """Simple ping endpoint for quick health checks"""
                    return jsonify({"status": "ok"})
                
                # Startup validation endpoint to verify the server is properly configured
                @app.route('/setup-validate', methods=['GET'])
                def setup_validate():
                    """Validates the server setup"""
                    import subprocess
                    
                    # Check if we can resolve DNS
                    dns_check = {"success": False}
                    try:
                        result = subprocess.run(['nslookup', 'google.com'], capture_output=True, text=True, timeout=5)
                        dns_check = {
                            "success": result.returncode == 0,
                            "output": result.stdout
                        }
                    except Exception as e:
                        dns_check["error"] = str(e)
                    
                    # Check disk space
                    disk_check = {"success": False}
                    try:
                        disk = psutil.disk_usage('/')
                        disk_check = {
                            "success": disk.percent < 90,  # Less than 90% used is success
                            "percent_used": disk.percent,
                            "free_gb": round(disk.free / (1024**3), 2)
                        }
                    except Exception as e:
                        disk_check["error"] = str(e)
                    
                    # Check ES connectivity if configured
                    es_check = {"configured": False}
                    if es_url and es_api_key:
                        es_check["configured"] = True
                        try:
                            from elasticsearch import Elasticsearch
                            es = Elasticsearch([es_url], api_key=es_api_key, request_timeout=5)
                            es_info = es.info()
                            es_check["success"] = True
                            es_check["version"] = es_info.get("version", {}).get("number", "unknown")
                        except Exception as e:
                            es_check["success"] = False
                            es_check["error"] = str(e)
                    
                    # Overall status
                    all_success = all([
                        dns_check.get("success", False),
                        disk_check.get("success", False),
                        # Only require ES if configured
                        not es_check.get("configured", False) or es_check.get("success", False)
                    ])
                    
                    return jsonify({
                        "success": all_success,
                        "timestamp": datetime.now().isoformat(),
                        "checks": {
                            "dns": dns_check,
                            "disk": disk_check,
                            "elasticsearch": es_check
                        }
                    })
                
                # Add handlers for other common errors
                @app.errorhandler(404)
                def not_found(e):
                    return jsonify({"error": "Not found", "message": str(e)}), 404
                
                @app.errorhandler(500)
                def server_error(e):
                    logger.error(f"Server error: {str(e)}")
                    return jsonify({"error": "Internal server error", "message": str(e)}), 500
                    
                @app.errorhandler(405)
                def method_not_allowed(e):
                    return jsonify({"error": "Method not allowed", "message": str(e)}), 405
                
                @app.errorhandler(400)
                def bad_request(e):
                    return jsonify({"error": "Bad request", "message": str(e)}), 400
                
                # Add after-request handler to ensure CORS headers are added to all responses
                @app.after_request
                def add_cors_headers(response):
                    # Ensure all responses have appropriate CORS headers
                    if 'Access-Control-Allow-Origin' not in response.headers:
                        cors_origins = os.environ.get('CORS_ALLOWED_ORIGINS', '*')
                        if cors_origins == '*':
                            response.headers['Access-Control-Allow-Origin'] = '*'
                        # For specific origins, the CORS extension will handle it
                    return response
                
                if __name__ == '__main__':
                    logger.info("Starting Flask application")
                    port = int(os.environ.get('PORT', 5000))
                    app.run(host='0.0.0.0', port=port)
              mode: "000644"
              owner: "root"
              group: "root"
            
            /opt/financial-news-engine/requirements.txt:
              content: |
                flask==2.3.3
                flask-cors==4.0.0
                elasticsearch==8.9.0
                requests==2.31.0
                python-dotenv==1.0.0
                gunicorn==21.2.0
                psutil==5.9.5
              mode: "000644"
              owner: "root"
              group: "root"
            
            /opt/financial-news-engine/verify_startup.sh:
              content: |
                #!/bin/bash
                set -e
                
                echo "Verifying backend service startup..."
                
                # Wait for the service to start
                for i in {1..12}; do
                  if curl -s http://localhost:5000/ping > /dev/null; then
                    echo "Service is responding to ping"
                    break
                  fi
                  
                  if [ $i -eq 12 ]; then
                    echo "ERROR: Service failed to start within 60 seconds"
                    exit 1
                  fi
                  
                  echo "Waiting for service to start (attempt $i/12)..."
                  sleep 5
                done
                
                # Verify setup validation endpoint
                SETUP_RESULT=$(curl -s http://localhost:5000/setup-validate)
                SUCCESS=$(echo $SETUP_RESULT | grep -o '"success": true' || echo "")
                
                if [ -n "$SUCCESS" ]; then
                  echo "Startup verification successful"
                  exit 0
                else
                  echo "WARNING: Setup validation failed:"
                  echo $SETUP_RESULT
                  exit 1
                fi
              mode: "000755"
              owner: "root"
              group: "root"
          
          commands:
            01_install_pip_packages:
              command: |
                cd /opt/financial-news-engine/
                pip3 install --no-cache-dir -r requirements.txt
            
            02_create_logs_dir:
              command: |
                mkdir -p /opt/financial-news-engine/logs
                chmod 755 /opt/financial-news-engine/logs
        
        configure_services:
          files:
            /etc/systemd/system/financial-news.service:
              content: !Sub |
                [Unit]
                Description=Financial News Engine Flask App
                After=network.target
                
                [Service]
                User=root
                WorkingDirectory=/opt/financial-news-engine
                ExecStart=/usr/local/bin/gunicorn --workers 3 --bind 0.0.0.0:5000 app:app --access-logfile logs/access.log --error-logfile logs/error.log --capture-output --log-level info
                Restart=always
                # Set a 60s startup timeout to ensure the service has enough time to initialize
                TimeoutStartSec=60
                # Ensure the service restarts after 10s if it fails
                RestartSec=10
                Environment=ELASTICSEARCH_URL=${ElasticsearchEndpoint}
                Environment=ELASTICSEARCH_API_KEY=${ElasticsearchApiKey}
                Environment=ELASTICSEARCH_INDEX=${ElasticsearchIndex}
                Environment=ES_NUMBER_OF_SHARDS=${EsNumberOfShards}
                Environment=ES_NUMBER_OF_REPLICAS=${EsNumberOfReplicas}
                Environment=ENVIRONMENT=${EnvironmentName}
                Environment=CORS_ALLOWED_ORIGINS=${CorsAllowedOrigins}
                
                [Install]
                WantedBy=multi-user.target
              mode: "000644"
              owner: "root"
              group: "root"
            
            /opt/financial-news-engine/.env:
              content: !Sub |
                ELASTICSEARCH_URL=${ElasticsearchEndpoint}
                ELASTICSEARCH_API_KEY=${ElasticsearchApiKey}
                ELASTICSEARCH_INDEX=${ElasticsearchIndex}
                ES_NUMBER_OF_SHARDS=${EsNumberOfShards}
                ES_NUMBER_OF_REPLICAS=${EsNumberOfReplicas}
                ENVIRONMENT=${EnvironmentName}
                CORS_ALLOWED_ORIGINS=${CorsAllowedOrigins}
              mode: "000644"
              owner: "root"
              group: "root"
            
            /opt/aws/amazon-cloudwatch-agent/etc/amazon-cloudwatch-agent.json:
              content: |
                {
                  "agent": {
                    "metrics_collection_interval": 60,
                    "run_as_user": "root"
                  },
                  "logs": {
                    "logs_collected": {
                      "files": {
                        "collect_list": [
                          {
                            "file_path": "/var/log/syslog",
                            "log_group_name": "/financial-news/system",
                            "log_stream_name": "{instance_id}"
                          },
                          {
                            "file_path": "/var/log/user-data.log",
                            "log_group_name": "/financial-news/initialization",
                            "log_stream_name": "{instance_id}"
                          },
                          {
                            "file_path": "/opt/financial-news-engine/logs/backend.log",
                            "log_group_name": "/financial-news/application",
                            "log_stream_name": "{instance_id}-app"
                          },
                          {
                            "file_path": "/opt/financial-news-engine/logs/error.log",
                            "log_group_name": "/financial-news/application",
                            "log_stream_name": "{instance_id}-error"
                          },
                          {
                            "file_path": "/opt/financial-news-engine/logs/access.log",
                            "log_group_name": "/financial-news/application",
                            "log_stream_name": "{instance_id}-access"
                          }
                        ]
                      }
                    }
                  },
                  "metrics": {
                    "metrics_collected": {
                      "disk": {
                        "measurement": [
                          "used_percent"
                        ],
                        "resources": [
                          "/"
                        ]
                      },
                      "mem": {
                        "measurement": [
                          "mem_used_percent"
                        ]
                      },
                      "statsd": {
                        "metrics_collection_interval": 10,
                        "metrics_aggregation_interval": 60,
                        "service_address": ":8125"
                      }
                    }
                  }
                }
              mode: "000644"
              owner: "root"
              group: "root"
        
        start_services:
          commands:
            01_reload_systemd:
              command: systemctl daemon-reload
            
            02_enable_financial_news:
              command: systemctl enable financial-news.service
            
            03_start_financial_news:
              command: systemctl start financial-news.service
            
            04_start_cloudwatch_agent:
              command: |
                systemctl daemon-reload
                systemctl enable amazon-cloudwatch-agent
                systemctl start amazon-cloudwatch-agent
    
    Properties:
      LaunchTemplateName: !Sub ${EnvironmentName}-backend-lt
      VersionDescription: Initial version
      LaunchTemplateData:
        ImageId: !Ref AMIId
        InstanceType: !Ref InstanceType
        KeyName: !Ref KeyName
        SecurityGroupIds:
          - !Ref BackendSecurityGroup
          - Fn::ImportValue: !Sub "${VpcStackName}-AppServerSG"
        IamInstanceProfile:
          Name: !Ref BackendInstanceProfile
        UserData:
          Fn::Base64: !Sub |
            #!/bin/bash
            
            # Log function
            function log {
              echo "$(date '+%Y-%m-%d %H:%M:%S') - $1" | tee -a /var/log/user-data.log
            }
            
            # Create a status file to track progress
            STATUS_FILE="/var/log/backend-init-status.txt"
            echo "STARTED" > $STATUS_FILE
            
            log "Starting backend initialization..."
            
            # Update system packages
            log "Updating system packages"
            apt-get update && apt-get install -y python3-pip
            
            # Install AWS CloudFormation helpers
            log "Installing AWS CloudFormation helpers"
            pip3 install https://s3.amazonaws.com/cloudformation-examples/aws-cfn-bootstrap-latest.tar.gz
            
            # Create app directory
            log "Creating application directory"
            mkdir -p /opt/financial-news-engine
            
            # Configure the instance
            log "Configuring the instance using cfn-init"
            /usr/local/bin/cfn-init -v \
              --stack ${AWS::StackName} \
              --resource BackendLaunchTemplate \
              --region ${AWS::Region}
            
            # Final status
            log "Initialization completed successfully"
            echo "COMPLETED" > $STATUS_FILE
            
            # Signal completion
            log "Signaling completion to CloudFormation"
            /usr/local/bin/cfn-signal -e $? --stack ${AWS::StackName} --resource BackendAutoScalingGroup --region ${AWS::Region}

  # Auto Scaling Group for Backend Servers
  BackendAutoScalingGroup:
    Type: AWS::AutoScaling::AutoScalingGroup
    DependsOn: HTTPSListener
    Properties:
      AutoScalingGroupName: !Sub ${EnvironmentName}-backend-asg
      LaunchTemplate:
        LaunchTemplateId: !Ref BackendLaunchTemplate
        Version: !GetAtt BackendLaunchTemplate.LatestVersionNumber
      MinSize: !Ref MinSize
      MaxSize: !Ref MaxSize
      DesiredCapacity: !Ref DesiredCapacity
      VPCZoneIdentifier:
        - Fn::ImportValue: !Sub "${VpcStackName}-PrivateSubnet1ID"
        - Fn::ImportValue: !Sub "${VpcStackName}-PrivateSubnet2ID"
      TargetGroupARNs:
        - !Ref BackendTargetGroup
      HealthCheckType: ELB
      HealthCheckGracePeriod: 300
      Tags:
        - Key: Name
          Value: !Sub ${EnvironmentName}-backend-instance
          PropagateAtLaunch: true
        - Key: Environment
          Value: !Ref EnvironmentName
          PropagateAtLaunch: true

  # Application Load Balancer
  ApplicationLoadBalancer:
    Type: AWS::ElasticLoadBalancingV2::LoadBalancer
    Properties:
      Name: !Sub ${EnvironmentName}-backend-alb
      Scheme: internet-facing
      LoadBalancerAttributes:
        - Key: idle_timeout.timeout_seconds
          Value: '60'
      Subnets:
        - Fn::ImportValue: !Sub "${VpcStackName}-PublicSubnet1ID"
        - Fn::ImportValue: !Sub "${VpcStackName}-PublicSubnet2ID"
      SecurityGroups:
        - !Ref LoadBalancerSecurityGroup
      Tags:
        - Key: Name
          Value: !Sub ${EnvironmentName}-backend-alb
        - Key: Environment
          Value: !Ref EnvironmentName

  # HTTPS Listener
  HTTPSListener:
    Type: AWS::ElasticLoadBalancingV2::Listener
    Properties:
      LoadBalancerArn: !Ref ApplicationLoadBalancer
      Port: 443
      Protocol: HTTPS
      Certificates:
        - CertificateArn: !If 
            - HasDomainName
            - !Ref SSLCertificate
            - !Ref SSLCertificateArn
      DefaultActions:
        - Type: forward
          TargetGroupArn: !Ref BackendTargetGroup
      SslPolicy: ELBSecurityPolicy-TLS-1-2-2017-01

  # HTTP Listener (redirects to HTTPS)
  HTTPListener:
    Type: AWS::ElasticLoadBalancingV2::Listener
    Properties:
      LoadBalancerArn: !Ref ApplicationLoadBalancer
      Port: 80
      Protocol: HTTP
      DefaultActions:
        - Type: redirect
          RedirectConfig:
            Protocol: HTTPS
            Port: '443'
            Host: '#{host}'
            Path: '/#{path}'
            Query: '#{query}'
            StatusCode: HTTP_301

  # Target Group for Backend Servers
  BackendTargetGroup:
    Type: AWS::ElasticLoadBalancingV2::TargetGroup
    Properties:
      Name: !Sub ${EnvironmentName}-backend-tg
      Port: 5000
      Protocol: HTTP
      VpcId:
        Fn::ImportValue: !Sub "${VpcStackName}-VPCID"
      HealthCheckIntervalSeconds: 30
      HealthCheckPath: /health
      HealthCheckProtocol: HTTP
      HealthCheckTimeoutSeconds: 5
      HealthyThresholdCount: 2
      UnhealthyThresholdCount: 3
      TargetGroupAttributes:
        - Key: deregistration_delay.timeout_seconds
          Value: '20'
      Tags:
        - Key: Name
          Value: !Sub ${EnvironmentName}-backend-tg
        - Key: Environment
          Value: !Ref EnvironmentName

  # Auto Scaling Policies
  ScaleUpPolicy:
    Type: AWS::AutoScaling::ScalingPolicy
    Properties:
      AutoScalingGroupName: !Ref BackendAutoScalingGroup
      PolicyType: TargetTrackingScaling
      TargetTrackingConfiguration:
        PredefinedMetricSpecification:
          PredefinedMetricType: ASGAverageCPUUtilization
        TargetValue: 70.0

  # CloudWatch Alarms
  HighCPUAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmDescription: Alarm if CPU too high for more than 5 minutes
      MetricName: CPUUtilization
      Namespace: AWS/EC2
      Statistic: Average
      Period: 300
      EvaluationPeriods: 2
      Threshold: 85
      AlarmActions:
        - !Ref BackendSNSTopic
      Dimensions:
        - Name: AutoScalingGroupName
          Value: !Ref BackendAutoScalingGroup
      ComparisonOperator: GreaterThanThreshold

  # SNS Topic for Alarms
  BackendSNSTopic:
    Type: AWS::SNS::Topic
    Properties:
      DisplayName: !Sub ${EnvironmentName}-backend-alerts
      TopicName: !Sub ${EnvironmentName}-backend-alerts

Outputs:
  BackendALBDNSName:
    Description: DNS Name of the Application Load Balancer
    Value: !GetAtt ApplicationLoadBalancer.DNSName
    Export:
      Name: !Sub "${AWS::StackName}-BackendALBDNSName"
  
  BackendALBFullQualifiedDNSName:
    Description: Full DNS Name of the Application Load Balancer
    Value: !If
      - HasDomainName
      - !Sub https://${BackendDomainName}
      - !Sub https://${ApplicationLoadBalancer.DNSName}
    Export:
      Name: !Sub "${AWS::StackName}-BackendALBURL"
  
  BackendAutoScalingGroupName:
    Description: Auto Scaling Group Name
    Value: !Ref BackendAutoScalingGroup
    Export:
      Name: !Sub "${AWS::StackName}-BackendASGName"
  
  BackendSecurityGroupId:
    Description: Security Group ID for Backend Servers
    Value: !Ref BackendSecurityGroup
    Export:
      Name: !Sub "${AWS::StackName}-BackendSGID"
  
  BackendSNSTopicArn:
    Description: ARN of the SNS Topic for Backend Alerts
    Value: !Ref BackendSNSTopic
    Export:
      Name: !Sub "${AWS::StackName}-BackendSNSTopicARN"
  
  ElasticsearchSettings:
    Description: "Elasticsearch configuration used"
    Value: !Sub "URL: ${ElasticsearchEndpoint}, Index: ${ElasticsearchIndex}"
    Export:
      Name: !Sub "${AWS::StackName}-ElasticsearchSettings"
  
  SSLCertificateArn:
    Description: ARN of the SSL certificate
    Value: !If
      - HasDomainName
      - !Ref SSLCertificate
      - !Ref SSLCertificateArn
    Export:
      Name: !Sub "${AWS::StackName}-SSLCertificateArn" 