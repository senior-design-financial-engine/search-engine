version: 0.2

env:
  parameter-store:
    ELASTICSEARCH_API_KEY: "/financial-news/elasticsearch-api-key"
    ELASTICSEARCH_URL: "/financial-news/elasticsearch-url"
    ELASTICSEARCH_INDEX: "/financial-news/elasticsearch-index"
    ES_NUMBER_OF_SHARDS: "/financial-news/es-number-of-shards"
    ES_NUMBER_OF_REPLICAS: "/financial-news/es-number-of-replicas"

phases:
  install:
    runtime-versions:
      python: 3.9
    commands:
      - echo Installing deployment tools...
      - pip install --upgrade awscli
      - pip install boto3
  
  pre_build:
    commands:
      - echo Logging in to Amazon ECR...
      - aws ecr get-login-password --region $AWS_DEFAULT_REGION | docker login --username AWS --password-stdin $ECR_REPOSITORY_URI
      - COMMIT_HASH=$(echo $CODEBUILD_RESOLVED_SOURCE_VERSION | cut -c 1-7)
      - IMAGE_TAG=${COMMIT_HASH:=latest}
      - echo Installing dependencies...
      - pip install -r backend/requirements.txt
      - pip install pytest pytest-cov
      - echo Running tests...
      - cd backend && python -m pytest --cov=. && cd ..
  
  build:
    commands:
      - echo Build started on `date`
      - echo Building the Docker image...
      - docker build -t $ECR_REPOSITORY_URI:latest -t $ECR_REPOSITORY_URI:$IMAGE_TAG -f backend/Dockerfile .
      - echo Build completed on `date`
  
  post_build:
    commands:
      - echo Pushing the Docker image...
      - docker push $ECR_REPOSITORY_URI:latest
      - docker push $ECR_REPOSITORY_URI:$IMAGE_TAG
      - echo Writing image definitions file...
      - aws cloudformation describe-stacks --stack-name search-engine-infra --query "Stacks[0].Outputs[?OutputKey=='EcsTaskDefinition'].OutputValue" --output text > taskdef.json
      - aws cloudformation describe-stacks --stack-name search-engine-infra --query "Stacks[0].Outputs[?OutputKey=='EcsCluster'].OutputValue" --output text > cluster.txt
      - aws cloudformation describe-stacks --stack-name search-engine-infra --query "Stacks[0].Outputs[?OutputKey=='EcsService'].OutputValue" --output text > service.txt
      - echo Preparing deployment scripts...
      - mkdir -p deploy_scripts
      - cat > deploy_scripts/create_env_file.sh << 'EOF'
#!/bin/bash
# Create .env file with environment variables by fetching directly from SSM Parameter Store
echo "Fetching credentials from SSM Parameter Store..."

# Get parameters from SSM Parameter Store
ES_URL=$(aws ssm get-parameter --name "/financial-news/elasticsearch-url" --with-decryption --query "Parameter.Value" --output text)
ES_API_KEY=$(aws ssm get-parameter --name "/financial-news/elasticsearch-api-key" --with-decryption --query "Parameter.Value" --output text)
ES_INDEX=$(aws ssm get-parameter --name "/financial-news/elasticsearch-index" --with-decryption --query "Parameter.Value" --output text)
ES_SHARDS=$(aws ssm get-parameter --name "/financial-news/es-number-of-shards" --with-decryption --query "Parameter.Value" --output text)
ES_REPLICAS=$(aws ssm get-parameter --name "/financial-news/es-number-of-replicas" --with-decryption --query "Parameter.Value" --output text)

# Create the .env file
cat > /opt/search-engine/.env << EOL
ELASTICSEARCH_URL=$ES_URL
ELASTICSEARCH_API_KEY=$ES_API_KEY
ELASTICSEARCH_INDEX=$ES_INDEX
ES_NUMBER_OF_SHARDS=$ES_SHARDS
ES_NUMBER_OF_REPLICAS=$ES_REPLICAS
EOL

# Set secure permissions
chmod 600 /opt/search-engine/.env
echo "Created .env file with environment variables from SSM Parameter Store"
EOF
      - cat > deploy_scripts/prepare_check_es.sh << 'EOF'
#!/bin/bash
# Make sure check_es_connection.py is in the right place and executable
mkdir -p /opt/search-engine/backend
cp /opt/search-engine/backend/check_es_connection.py /opt/search-engine/backend/check_es_connection.py
chmod +x /opt/search-engine/backend/check_es_connection.py
echo "Prepared check_es_connection.py script"
EOF
      - cat > deploy_scripts/install_dependencies.sh << 'EOF'
#!/bin/bash
# Install Python dependencies
echo "Installing Python dependencies..."
pip3 install -r /opt/search-engine/backend/requirements.txt

# Ensure psutil is installed (explicit installation to handle system dependencies)
echo "Ensuring psutil is installed..."
pip3 install psutil==5.9.5

# Check if psutil is installed correctly
python3 -c "import psutil; print('psutil version:', psutil.__version__)"
if [ $? -ne 0 ]; then
  echo "WARNING: Failed to import psutil. Installing system dependencies and trying again..."
  # Install system dependencies that might be needed for psutil
  apt-get update -y || yum update -y
  apt-get install -y python3-dev gcc || yum install -y python3-devel gcc
  pip3 install --no-cache-dir --force-reinstall psutil==5.9.5
  
  # Verify installation
  python3 -c "import psutil; print('psutil version:', psutil.__version__)"
  if [ $? -ne 0 ]; then
    echo "ERROR: Failed to install psutil after multiple attempts"
    # Continue anyway - we don't want to fail the deployment for this
  fi
fi

echo "Dependencies installation completed"
EOF
      - cat > deploy_scripts/create_service_file.sh << 'EOF'
#!/bin/bash
# Create systemd service file
cat > /etc/systemd/system/search-engine-backend.service << EOL
[Unit]
Description=Search Engine Backend Service
After=network.target

[Service]
User=root
WorkingDirectory=/opt/search-engine/backend
EnvironmentFile=/opt/search-engine/.env
Environment="PYTHONUNBUFFERED=1"
ExecStart=/usr/bin/python3 -m gunicorn --workers 3 --bind 0.0.0.0:5000 app:app --access-logfile logs/access.log --error-logfile logs/error.log --capture-output --log-level info
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
EOL
chmod 644 /etc/systemd/system/search-engine-backend.service
echo "Created systemd service file"
EOF
      - cat > deploy_scripts/verify_startup.sh << 'EOF'
#!/bin/bash
# Verify backend service startup and test Elasticsearch connectivity
echo "Waiting for backend service to start up..."
sleep 10
# Check if the service is running
systemctl is-active --quiet search-engine-backend
if [ $? -ne 0 ]; then
  echo "ERROR: search-engine-backend service is not running"
  systemctl status search-engine-backend
  exit 1
fi
echo "Backend service is running"

# Check Elasticsearch connectivity
echo "Testing Elasticsearch connectivity..."
mkdir -p /opt/search-engine/scripts
cp /opt/search-engine/scripts/verify_es.sh /opt/search-engine/scripts/verify_es.sh
chmod +x /opt/search-engine/scripts/verify_es.sh
/opt/search-engine/scripts/verify_es.sh
if [ $? -ne 0 ]; then
  echo "WARNING: Elasticsearch connectivity check failed"
  # Don't fail deployment if ES check fails, log it and continue
  echo "Continuing deployment despite Elasticsearch connectivity issues"
fi
EOF
      - chmod +x deploy_scripts/create_env_file.sh
      - chmod +x deploy_scripts/prepare_check_es.sh
      - chmod +x deploy_scripts/install_dependencies.sh
      - chmod +x deploy_scripts/create_service_file.sh
      - chmod +x deploy_scripts/verify_startup.sh
      - echo Preparing SSM commands...
      - cat > deploy_commands.json << EOF
{
  "commands": [
    "mkdir -p /opt/search-engine/backend",
    "mkdir -p /opt/search-engine/scripts",
    "aws s3 cp s3://${ARTIFACT_BUCKET}/${ARTIFACT_KEY} /tmp/artifacts.zip",
    "unzip -o /tmp/artifacts.zip -d /opt/search-engine/",
    "chmod +x /opt/search-engine/deploy_scripts/create_env_file.sh",
    "chmod +x /opt/search-engine/deploy_scripts/prepare_check_es.sh",
    "chmod +x /opt/search-engine/deploy_scripts/install_dependencies.sh",
    "chmod +x /opt/search-engine/deploy_scripts/create_service_file.sh",
    "chmod +x /opt/search-engine/deploy_scripts/verify_startup.sh",
    "/opt/search-engine/deploy_scripts/create_env_file.sh",
    "/opt/search-engine/deploy_scripts/prepare_check_es.sh",
    "/opt/search-engine/deploy_scripts/install_dependencies.sh",
    "/opt/search-engine/deploy_scripts/create_service_file.sh",
    "systemctl restart search-engine-backend",
    "/opt/search-engine/deploy_scripts/verify_startup.sh"
  ]
}
EOF
      - echo Updating service...
      - aws ecs update-service --cluster $(cat cluster.txt) --service $(cat service.txt) --force-new-deployment
      - echo Deployment update initiated...

artifacts:
  files:
    - appspec.yml
    - taskdef.json
    - cluster.txt
    - service.txt
    - deploy_commands.json
    - backend/**/*
    - deploy_scripts/**/*
    - scripts/**/*
  discard-paths: no

cache:
  paths:
    - '/root/.cache/pip' 